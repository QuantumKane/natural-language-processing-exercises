{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aquisition Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape the article text from the following pages:\n",
    "- https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    "- https://codeup.com/data-science-myths/\n",
    "- https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    "- https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    "- https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the http request and turn the response into a beautiful soup object\n",
    "\n",
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'}\n",
    "response = requests.get(url, headers=headers)\n",
    "html = response.text\n",
    "soup = bs4.BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_div = soup.select('.jupiterx-content')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = soup.find('title').text\n",
    "# title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator_div.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(urls, cached=False):\n",
    "    dict = []\n",
    "    \n",
    "    for url in urls:\n",
    "        headers = {'User-Agent': 'Codeup Data Science'} \n",
    "        response = requests.get(url, headers=headers)\n",
    "        # \n",
    "        soup = bs4.BeautifulSoup(response.text)\n",
    "        website = soup.find('div', class_='jupiterx-post-content')\n",
    "        \n",
    "        # creates empty dictionary\n",
    "        website_dict = {'title':[], 'content':[]}\n",
    "        # adds title to dictionary\n",
    "        website_dict['title'] = soup.title.string\n",
    "        # adds content to dictionary\n",
    "        website_dict['content'] = website.text\n",
    "        \n",
    "        # adds this dict to the url list\n",
    "        dict.append(website_dict)\n",
    "        \n",
    "    # make it a dataframe\n",
    "    dict = pd.DataFrame(dict)\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is He...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths - Codeup</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair - ...</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is He...   \n",
       "1                        Data Science Myths - Codeup   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3  10 Tips to Crush It at the SA Tech Job Fair - ...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "        'https://codeup.com/data-science-myths/', \n",
    "        'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/', \n",
    "        'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "        'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "codeup_df = get_blog_articles(urls, cached=False)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 Tips to Crush It at the SA Tech Job Fair - Codeup'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.title[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://inshorts.com/en/read/entertainment'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div class=\"news-card z-depth-1\" itemscope=\"\" itemtype=\"http://schema.org/NewsArticle\">\n",
       "<span content=\"\" itemid=\"https://inshorts.com/en/news/2-designers-pledge-to-never-work-with-kangana-after-twitter-suspends-her-account-1620141915434\" itemprop=\"mainEntityOfPage\" itemscope=\"\" itemtype=\"https://schema.org/WebPage\"></span>\n",
       "<span itemprop=\"author\" itemscope=\"itemscope\" itemtype=\"https://schema.org/Person\">\n",
       "<span content=\"Daisy Mowke\" itemprop=\"name\"></span>\n",
       "</span>\n",
       "<span content=\"2 designers pledge to never work with Kangana after Twitter suspends her account\" itemprop=\"description\"></span>\n",
       "<span itemprop=\"image\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\">\n",
       "<meta content=\"https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2021/05_may/4_tue/img_1620140528612_710.jpg?\" itemprop=\"url\"/>\n",
       "<meta content=\"864\" itemprop=\"width\"/>\n",
       "<meta content=\"483\" itemprop=\"height\"/>\n",
       "</span>\n",
       "<span itemprop=\"publisher\" itemscope=\"itemscope\" itemtype=\"https://schema.org/Organization\">\n",
       "<span content=\"https://inshorts.com/\" itemprop=\"url\"></span>\n",
       "<span content=\"Inshorts\" itemprop=\"name\"></span>\n",
       "<span itemprop=\"logo\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\">\n",
       "<span content=\"https://assets.inshorts.com/inshorts/images/v1/variants/jpg/m/2018/11_nov/21_wed/img_1542823931298_497.jpg\" itemprop=\"url\"></span>\n",
       "<meta content=\"400\" itemprop=\"width\"/>\n",
       "<meta content=\"60\" itemprop=\"height\"/>\n",
       "</span>\n",
       "</span>\n",
       "<div class=\"news-card-image\" style=\"background-image: url('https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2021/05_may/4_tue/img_1620140528612_710.jpg?')\">\n",
       "</div>\n",
       "<div class=\"news-card-title news-right-box\">\n",
       "<a class=\"clickable\" href=\"/en/news/2-designers-pledge-to-never-work-with-kangana-after-twitter-suspends-her-account-1620141915434\" onclick=\"ga('send', {'hitType': 'event', 'eventCategory': 'TitleOfNews', 'eventAction': 'clicked', 'eventLabel': '2%20designers%20pledge%20to%20never%20work%20with%20Kangana%20after%20Twitter%20suspends%20her%20account)' });\" style=\"color:#44444d!important\">\n",
       "<span itemprop=\"headline\">2 designers pledge to never work with Kangana after Twitter suspends her account</span>\n",
       "</a>\n",
       "<div class=\"news-card-author-time news-card-author-time-in-title\">\n",
       "<a href=\"/prev/en/news/2-designers-pledge-to-never-work-with-kangana-after-twitter-suspends-her-account-1620141915434\"><span class=\"short\">short</span></a> by <span class=\"author\">Daisy Mowke</span> / \n",
       "      <span class=\"time\" content=\"2021-05-04T15:25:15.000Z\" itemprop=\"datePublished\">08:55 pm</span> on <span clas=\"date\">04 May 2021,Tuesday</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"news-card-content news-right-box\">\n",
       "<div itemprop=\"articleBody\">After Twitter permanently suspended Kangana Ranaut's account, fashion designers Anand Bhushan and Rimzim Dadu issued statements saying they're disassociating themselves and their brands from the actress. \"We as a brand don't support hate speech,\" said Anand. \"We're removing all posts of past collaboration with Kangana...and pledge to not engage in any future association with her,\" wrote Rimzim.</div>\n",
       "<div class=\"news-card-author-time news-card-author-time-in-content\">\n",
       "<a href=\"/prev/en/news/2-designers-pledge-to-never-work-with-kangana-after-twitter-suspends-her-account-1620141915434\"><span class=\"short\">short</span></a> by <span class=\"author\">Daisy Mowke</span> / \n",
       "      <span class=\"time\" content=\"2021-05-04T15:25:15.000Z\" itemprop=\"dateModified\">08:55 pm</span> on <span class=\"date\">04 May</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"news-card-footer news-right-box\">\n",
       "<div class=\"read-more\">read more at <a class=\"source\" href=\"https://www.thequint.com/amp/story/entertainment/celebrities/designers-brands-boycott-kangana-ranaut-after-twitter-suspension-rimzim-dadu-anand-bhushan-swara-bhaskar?utm_campaign=fullarticle&amp;utm_medium=referral&amp;utm_source=inshorts \" onclick=\"ga('send', {'hitType': 'event', 'eventCategory': 'ReadMore', 'eventAction': 'clicked', 'eventLabel': 'The%20Quint' });\" target=\"_blank\">The Quint</a></div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape a ResultSet of all the news cards on the page and look at first card\n",
    "\n",
    "cards = soup.find_all('div', class_='news-card')\n",
    "print(type(cards))\n",
    "cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 designers pledge to never work with Kangana after Twitter suspends her account',\n",
       " \"Pia Bajpiee's brother dies of COVID hrs after her appeal for ventilator bed\",\n",
       " 'YRF requests Maha CM to help them vaccinate 30,000 cine workers',\n",
       " \"I'm doing well with mild symptoms: Allu Arjun after testing COVID +ve\",\n",
       " \"Permanent relief: Kubbra on Twitter suspending Kangana's account\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the title of each news card to list titles\n",
    "\n",
    "titles = []\n",
    "for card in cards:\n",
    "    title = card.find('span', itemprop='headline').text\n",
    "    titles.append(title)\n",
    "    \n",
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Daisy Mowke', 'Bulbul Sharma', 'Udit Gupta', 'Udit Gupta', 'Bulbul Sharma']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the author of the news card to list authors\n",
    "\n",
    "authors = []\n",
    "for card in cards:\n",
    "    author = card.find('span', class_='author').text\n",
    "    authors.append(author)\n",
    "    \n",
    "authors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After Twitter permanently suspended Kangana Ranaut\\'s account, fashion designers Anand Bhushan and Rimzim Dadu issued statements saying they\\'re disassociating themselves and their brands from the actress. \"We as a brand don\\'t support hate speech,\" said Anand. \"We\\'re removing all posts of past collaboration with Kangana...and pledge to not engage in any future association with her,\" wrote Rimzim.',\n",
       " 'Actress Pia Bajpiee on Tuesday informed that she has lost her brother due to COVID-19. She tweeted the news of his death only hours after she appealed for a ventilator bed for him in the Farrukhabad district of Uttar Pradesh. \"I need urgent help...my brother is dying...we are already in mess,\" Pia wrote at around 7 am. ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the text of each article to a list of texts\n",
    "\n",
    "texts = []\n",
    "for card in cards:\n",
    "    text = card.find('div', itemprop='articleBody').text\n",
    "    texts.append(text)\n",
    "    \n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list, articles, to hold the dictionaries for each article\n",
    "articles = []\n",
    "\n",
    "# Loop through each news card on the page and get what we want\n",
    "for card in cards:\n",
    "    title = card.find('span', itemprop='headline' ).text\n",
    "    author = card.find('span', class_='author').text\n",
    "    content = card.find('div', itemprop='articleBody').text\n",
    "    \n",
    "    # Create a dictionary, article, for each news card\n",
    "    article = {'title': title, 'author': author, 'content': content}\n",
    "    \n",
    "    # Add the dictionary, article, to our list of dictionaries, articles.\n",
    "    articles.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': '2 designers pledge to never work with Kangana after Twitter suspends her account',\n",
       "  'author': 'Daisy Mowke',\n",
       "  'content': 'After Twitter permanently suspended Kangana Ranaut\\'s account, fashion designers Anand Bhushan and Rimzim Dadu issued statements saying they\\'re disassociating themselves and their brands from the actress. \"We as a brand don\\'t support hate speech,\" said Anand. \"We\\'re removing all posts of past collaboration with Kangana...and pledge to not engage in any future association with her,\" wrote Rimzim.'},\n",
       " {'title': \"Pia Bajpiee's brother dies of COVID hrs after her appeal for ventilator bed\",\n",
       "  'author': 'Bulbul Sharma',\n",
       "  'content': 'Actress Pia Bajpiee on Tuesday informed that she has lost her brother due to COVID-19. She tweeted the news of his death only hours after she appealed for a ventilator bed for him in the Farrukhabad district of Uttar Pradesh. \"I need urgent help...my brother is dying...we are already in mess,\" Pia wrote at around 7 am. '}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we see our list contains 24 dictionaries for news cards\n",
    "\n",
    "print(len(articles))\n",
    "articles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles(cache=False):\n",
    "    '''\n",
    "    This function uses a cache parameter with default cache == False to give the option of \n",
    "    returning in a df of inshorts topics and info by reading a csv file or\n",
    "    of doing a fresh scrape of inshort pages with topics business, sports, technology,\n",
    "    and entertainment and writing the returned df to a csv file.\n",
    "    '''\n",
    "    # default to read in a csv instead of scrape for df\n",
    "    if cache == False:\n",
    "        df = pd.read_csv('articles.csv', index_col=0)\n",
    "        \n",
    "    # cache == True completes a fresh scrape for df    \n",
    "    else:\n",
    "    \n",
    "        # Set base_url and headers that will be used in get request\n",
    "\n",
    "        base_url = 'https://inshorts.com/en/read/'\n",
    "        headers = {'User-Agent': 'Codeup Data Science'}\n",
    "        \n",
    "        # List of topics to scrape\n",
    "        topics = ['business', 'sports', 'technology', 'entertainment']\n",
    "\n",
    "        # Create an empty list, articles, to hold our dictionaries\n",
    "        articles = []\n",
    "\n",
    "        for topic in topics:\n",
    "\n",
    "            # Get a response object from the main inshorts page\n",
    "            response = requests.get(base_url + topic, headers=headers)\n",
    "\n",
    "            # Create soup object using response from inshort\n",
    "            soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Scrape a ResultSet of all the news cards on the page\n",
    "            cards = soup.find_all('div', class_='news-card')\n",
    "\n",
    "            # Loop through each news card on the page and get what we want\n",
    "            for card in cards:\n",
    "                title = card.find('span', itemprop='headline' ).text\n",
    "                author = card.find('span', class_='author').text\n",
    "                content = card.find('div', itemprop='articleBody').text\n",
    "\n",
    "                # Create a dictionary, article, for each news card\n",
    "                article = ({'topic': topic, \n",
    "                            'title': title, \n",
    "                            'author': author, \n",
    "                            'content': content})\n",
    "\n",
    "                # Add the dictionary, article, to our list of dictionaries, articles.\n",
    "                articles.append(article)\n",
    "            \n",
    "        # return it as a DataFrame\n",
    "        df = pd.DataFrame(articles)\n",
    "        \n",
    "        # write df to csv for future use\n",
    "        df.to_csv('articles.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>India underestimated the coronavirus: Raghuram...</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>Speaking about India's second COVID-19 wave, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Air India pilots demand vaccination on priorit...</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>Indian Commercial Pilots Association (ICPA) on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>World's biggest jeweller says it will no longe...</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>Pandora, the world's biggest jeweller, has sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>South Korea's richest woman gets fortune worth...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>South Korea’s richest woman Hong Ra-hee added ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>M&amp;M advances annual maintenance plant shutdown...</td>\n",
       "      <td>Krishna Raj</td>\n",
       "      <td>Mahindra &amp; Mahindra (M&amp;M) said that it has adv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title        author  \\\n",
       "0  business  India underestimated the coronavirus: Raghuram...  Kiran Khatri   \n",
       "1  business  Air India pilots demand vaccination on priorit...  Kiran Khatri   \n",
       "2  business  World's biggest jeweller says it will no longe...  Kiran Khatri   \n",
       "3  business  South Korea's richest woman gets fortune worth...  Anmol Sharma   \n",
       "4  business  M&M advances annual maintenance plant shutdown...   Krishna Raj   \n",
       "\n",
       "                                             content  \n",
       "0  Speaking about India's second COVID-19 wave, f...  \n",
       "1  Indian Commercial Pilots Association (ICPA) on...  \n",
       "2  Pandora, the world's biggest jeweller, has sai...  \n",
       "3  South Korea’s richest woman Hong Ra-hee added ...  \n",
       "4  Mahindra & Mahindra (M&M) said that it has adv...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our function with cache == True to do a fresh scrape and write to `articles.csv`\n",
    "\n",
    "news_df = get_news_articles(cache=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entertainment    25\n",
       "business         25\n",
       "sports           25\n",
       "technology       24\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mohanlal's 'Drishyam 2' to get a Hindi remake\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.title[96]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a string to use throughout the exercise\n",
    "\n",
    "string_thing = \"A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKC', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a noncapturing version of regular parentheses matches whatever regular expression is inside the parentheses but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(string_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses , but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(string_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A non-captur version of regular parentheses. match whatev regular express is insid the parentheses, but the substr match by the group cannot be retriev after perform a match or referenc later in the pattern.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(string_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/stevekane/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the first time.\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(string_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stevekane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "    # Add in 'extra_words' to stopword_list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A non-capturing version regular parentheses. Matches whatever regular expression inside parentheses, substring matched group retrieved performing match or referenced later pattern.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern.', extra_words=['cannot'], exclude_words=['or'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\\\n",
    "                            .apply(lemmatize)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean).apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean).apply(lemmatize)\n",
    "    \n",
    "    return df[['title', column, 'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is He...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "      <td>rumor true time arrived codeup officially open...</td>\n",
       "      <td>the rumor are true the time ha arriv codeup ha...</td>\n",
       "      <td>the rumor are true the time ha arrived codeup ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths - Codeup</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "      <td>dimitri antoniou maggie giust data science big...</td>\n",
       "      <td>by dimitri antoni and maggi giust data scienc ...</td>\n",
       "      <td>by dimitri antoniou and maggie giust data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "      <td>dimitri antoniou week ago codeup launched imme...</td>\n",
       "      <td>by dimitri antoni a week ago codeup launch our...</td>\n",
       "      <td>by dimitri antoniou a week ago codeup launched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair - ...</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "      <td>sa tech job fair third biannual san antonio te...</td>\n",
       "      <td>sa tech job fair the third biannual san antoni...</td>\n",
       "      <td>sa tech job fair the third biannual san antoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>competitor bootcamps closing model danger prog...</td>\n",
       "      <td>competitor bootcamp are close is the model in ...</td>\n",
       "      <td>competitor bootcamps are closing is the model ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is He...   \n",
       "1                        Data Science Myths - Codeup   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3  10 Tips to Crush It at the SA Tech Job Fair - ...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The rumors are true! The time has arrived. Cod...   \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...   \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...   \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  rumor true time arrived codeup officially open...   \n",
       "1  dimitri antoniou maggie giust data science big...   \n",
       "2  dimitri antoniou week ago codeup launched imme...   \n",
       "3  sa tech job fair third biannual san antonio te...   \n",
       "4  competitor bootcamps closing model danger prog...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  the rumor are true the time ha arriv codeup ha...   \n",
       "1  by dimitri antoni and maggi giust data scienc ...   \n",
       "2  by dimitri antoni a week ago codeup launch our...   \n",
       "3  sa tech job fair the third biannual san antoni...   \n",
       "4  competitor bootcamp are close is the model in ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  the rumor are true the time ha arrived codeup ...  \n",
       "1  by dimitri antoniou and maggie giust data scie...  \n",
       "2  by dimitri antoniou a week ago codeup launched...  \n",
       "3  sa tech job fair the third biannual san antoni...  \n",
       "4  competitor bootcamps are closing is the model ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(codeup_df, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
